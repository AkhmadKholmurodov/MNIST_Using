{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aX1pleCB2Oa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be22ee9-b700-4a1a-b23f-b1e4554dd4e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# Google Colab에서 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import time\n",
        "from music21 import converter, instrument, note, chord, stream, midi\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Melody-RNN Format is a sequence of 8-bit integers indicating the following:\n",
        "# MELODY_NOTE_ON = [0, 127] # (note on at that MIDI pitch)\n",
        "MELODY_NOTE_OFF = 83 # (stop playing all previous notes)\n",
        "MELODY_NO_EVENT = 84 # (no change from previous event)\n",
        "\n",
        "# Each element in the sequence lasts for one sixteenth note.\n",
        "# This can encode monophonic music only\n",
        "def streamToNoteArray(stream):\n",
        "   \"\"\"\n",
        "   Convert a Music21 sequence to a numpy array of int8s into Melody-RNN format:\n",
        "   0-127 - note on at specified pitch\n",
        "   128 - note off\n",
        "   129 - no event\n",
        "   \"\"\"\n",
        "   # Part one, extract from stream\n",
        "   total_length = np.int(np.round(stream.flat.highestTime / 0.25)) # in semiquavers\n",
        "   stream_list = []\n",
        "   for element in stream.flat:\n",
        "       if isinstance(element, note.Note):\n",
        "           stream_list.append([np.round(element.offset / 0.25), np.round(element.quarterLength / 0.25), element.pitch.midi])\n",
        "       elif isinstance(element, chord.Chord):\n",
        "           stream_list.append([np.round(element.offset / 0.25), np.round(element.quarterLength / 0.25), element.sortAscending().pitches[-1].midi])\n",
        "   np_stream_list = np.array(stream_list, dtype=np.int)\n",
        "   df = pd.DataFrame({'pos': np_stream_list.T[0], 'dur': np_stream_list.T[1], 'pitch': np_stream_list.T[2]})\n",
        "   df = df.sort_values(['pos','pitch'], ascending=[True, False]) # sort the dataframe properly\n",
        "   df = df.drop_duplicates(subset=['pos']) # drop duplicate values\n",
        "\n",
        "   # part 2, convert into a sequence of note events\n",
        "   output = np.zeros(total_length+1, dtype=np.int16) + np.int16(MELODY_NO_EVENT) # set array full of no events by default.\n",
        "   # Fill in the output list\n",
        "   for i in range(total_length):\n",
        "       if not df[df.pos==i].empty:\n",
        "           n = df[df.pos==i].iloc[0] # pick the highest pitch at each semiquaver\n",
        "           output[i] = n.pitch # set note on\n",
        "           output[i+n.dur] = MELODY_NOTE_OFF\n",
        "   return output\n",
        "\n",
        "# 기존 코드에서 사용한 MIDI 파일 경로\n",
        "midi_files = glob.glob(\"/content/drive/MyDrive/GAN/lofi/*.mid\")\n",
        "print(midi_files)\n",
        "\n",
        "\n",
        "new_midi_files = glob.glob(\"/content/path/to/your/midi/files/*.mid\")\n",
        "\n",
        "training_arrays = []\n",
        "for f in midi_files + new_midi_files:\n",
        "   start = time.perf_counter()\n",
        "   try:\n",
        "       s = converter.parse(f)\n",
        "   except:\n",
        "       continue\n",
        "   arr = streamToNoteArray(s.parts[0]) # just extract first voice\n",
        "   arr = np.where(arr > 84, 84, arr)\n",
        "   value = arr.shape[0] // 4\n",
        "   arr = arr[:value * 4]\n",
        "   arr = arr.reshape(-1, 4)\n",
        "   arr = arr.astype(np.float16)\n",
        "   training_arrays.append(arr)\n",
        "   print(\"Converted:\", f, \"it took\", time.perf_counter() - start)\n",
        "\n",
        "training_dataset = np.array(training_arrays)\n",
        "np.savez('/content/drive/MyDrive/GAN/lo-fi.npz', train=training_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab에서 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import time\n",
        "from music21 import converter, instrument, note, chord, stream, midi\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Melody-RNN Format is a sequence of 8-bit integers indicating the following:\n",
        "# MELODY_NOTE_ON = [0, 127] # (note on at that MIDI pitch)\n",
        "MELODY_NOTE_OFF = 83 # (stop playing all previous notes)\n",
        "MELODY_NO_EVENT = 84 # (no change from previous event)\n",
        "\n",
        "# Each element in the sequence lasts for one sixteenth note.\n",
        "# This can encode monophonic music only\n",
        "def streamToNoteArray(stream):\n",
        "    \"\"\"\n",
        "    Convert a Music21 sequence to a numpy array of int8s into Melody-RNN format:\n",
        "    0-127 - note on at specified pitch\n",
        "    128 - note off\n",
        "    129 - no event\n",
        "    \"\"\"\n",
        "    # Part one, extract from stream\n",
        "    total_length = np.int(np.round(stream.flat.highestTime / 0.25)) # in semiquavers\n",
        "    stream_list = []\n",
        "    for element in stream.flat:\n",
        "        if isinstance(element, note.Note):\n",
        "            stream_list.append([np.round(element.offset / 0.25), np.round(element.quarterLength / 0.25), element.pitch.midi])\n",
        "        elif isinstance(element, chord.Chord):\n",
        "            stream_list.append([np.round(element.offset / 0.25), np.round(element.quarterLength / 0.25), element.sortAscending().pitches[-1].midi])\n",
        "    np_stream_list = np.array(stream_list, dtype=np.int)\n",
        "    df = pd.DataFrame({'pos': np_stream_list.T[0], 'dur': np_stream_list.T[1], 'pitch': np_stream_list.T[2]})\n",
        "    df = df.sort_values(['pos','pitch'], ascending=[True, False]) # sort the dataframe properly\n",
        "    df = df.drop_duplicates(subset=['pos']) # drop duplicate values\n",
        "\n",
        "    # part 2, convert into a sequence of note events\n",
        "    output = np.zeros(total_length+1, dtype=np.int16) + np.int16(MELODY_NO_EVENT) # set array full of no events by default.\n",
        "    # Fill in the output list\n",
        "    for i in range(total_length):\n",
        "        if not df[df.pos==i].empty:\n",
        "            n = df[df.pos==i].iloc[0] # pick the highest pitch at each semiquaver\n",
        "            output[i] = n.pitch # set note on\n",
        "            output[i+n.dur] = MELODY_NOTE_OFF\n",
        "    return output\n",
        "\n",
        "# MIDI 파일에서 chords 추출\n",
        "def extract_chords(midi_file):\n",
        "    # MIDI 파일에서 코드 정보 추출 코드\n",
        "    # 예시: 모든 동시에 연주되는 노트 조합을 코드로 간주\n",
        "    midi_stream = converter.parse(midi_file)\n",
        "    chords = []\n",
        "    for element in midi_stream.flat:\n",
        "        if isinstance(element, chord.Chord):\n",
        "            chord_pitches = [p.midi for p in element.pitches]\n",
        "            chords.append(chord_pitches)\n",
        "    return chords\n",
        "\n",
        "# MIDI 파일에서 style 추출 (가정: 템포와 박자를 스타일로 사용)\n",
        "def extract_style(midi_file):\n",
        "    midi_stream = converter.parse(midi_file)\n",
        "    tempo = midi_stream.metronomeMarkBoundaries()[0][2].getNumber()\n",
        "    time_signature = midi_stream.flattenedParts()[0].getTimeSignatures()[0]\n",
        "    style = [tempo, time_signature.numerator, time_signature.denominator]\n",
        "    return style\n",
        "\n",
        "# MIDI 파일에서 melody 추출\n",
        "def extract_melody(midi_file):\n",
        "    midi_stream = converter.parse(midi_file)\n",
        "    melody_stream = midi_stream.parts[0]  # 가정: 첫 번째 파트가 멜로디\n",
        "    melody = streamToNoteArray(melody_stream)\n",
        "    return melody\n",
        "\n",
        "# MIDI 파일에서 groove 추출 (가정: 박자 패턴을 groove로 사용)\n",
        "def extract_groove(midi_file):\n",
        "    midi_stream = converter.parse(midi_file)\n",
        "    groove = []\n",
        "    for element in midi_stream.flat:\n",
        "        if isinstance(element, note.Note):\n",
        "            groove.append(element.offset)\n",
        "    return groove\n",
        "\n",
        "# MIDI 파일 경로\n",
        "midi_files = glob.glob(\"/content/drive/MyDrive/GAN/lofi/*.mid\")\n",
        "\n",
        "# museGAN 입력값 전처리 함수 (가정)\n",
        "def preprocess_chords(chords):\n",
        "    # 코드 전처리 코드\n",
        "    return preprocessed_chords\n",
        "\n",
        "def preprocess_style(style):\n",
        "    # 스타일 전처리 코드\n",
        "    return preprocessed_style\n",
        "\n",
        "def preprocess_melody(melody):\n",
        "    # 멜로디 전처리 코드\n",
        "    return preprocessed_melody\n",
        "\n",
        "def preprocess_groove(groove):\n",
        "    # 그루브 전처리 코드\n",
        "    return preprocessed_groove\n",
        "\n",
        "# museGAN 모델 (가정)\n",
        "def museGAN_model(chords, style, melody, groove):\n",
        "    # museGAN 모델 코드\n",
        "    return output\n",
        "\n",
        "for f in midi_files:\n",
        "    chords = extract_chords(f)\n",
        "    style = extract_style(f)\n",
        "    melody = extract_melody(f)\n",
        "    groove = extract_groove(f)\n",
        "\n",
        "    chords = preprocess_chords(chords)\n",
        "    style = preprocess_style(style)\n",
        "    melody = preprocess_melody(melody)\n",
        "    groove = preprocess_groove(groove)\n",
        "\n",
        "    output = museGAN_model(chords, style, melody, groove)\n",
        "    print(\"Generated output for\", f)\n",
        "    # 출력 결과 처리 코드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqcs_AEXCa-e",
        "outputId": "1ba00ef6-8fbc-40eb-9234-1a563d45177b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}